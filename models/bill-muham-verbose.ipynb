{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. 準備環境","metadata":{"id":"lFEY4hkThYI3"}},{"cell_type":"markdown","source":"## 1.1 匯入檔案處理與圖像顯示模組","metadata":{}},{"cell_type":"code","source":"import os # 處理檔案和目錄\nimport glob # 查找符合特定模式的所有路徑名\n\n# 在 Jupyter Notebook 或 IPython 環境中顯示圖像\nfrom IPython.display import Image, display\nfrom IPython import display","metadata":{"id":"s-a3GfdZhY0t","executionInfo":{"status":"ok","timestamp":1674148368192,"user_tz":-300,"elapsed":936,"user":{"displayName":"Muhammad Moin","userId":"09308091267031599057"}},"execution":{"iopub.status.busy":"2024-08-20T02:29:34.145097Z","iopub.execute_input":"2024-08-20T02:29:34.146403Z","iopub.status.idle":"2024-08-20T02:29:34.151577Z","shell.execute_reply.started":"2024-08-20T02:29:34.146330Z","shell.execute_reply":"2024-08-20T02:29:34.150509Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# 清理輸出區域，這樣在重新執行程式時，不會看到先前的輸出結果。\n# 這有助於保持 Notebook 的整潔，避免混淆舊的與新的輸出內容。\ndisplay.clear_output()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T02:29:34.153556Z","iopub.execute_input":"2024-08-20T02:29:34.153915Z","iopub.status.idle":"2024-08-20T02:29:34.161656Z","shell.execute_reply.started":"2024-08-20T02:29:34.153890Z","shell.execute_reply":"2024-08-20T02:29:34.160695Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## 1.2 定義工作目錄","metadata":{}},{"cell_type":"markdown","source":"我們可以使用 `os.getcwd()` 取得**當前工作目錄的路徑**，並將其儲存到 `HOME` 變數中，並且把它印出來。\n\n在深度學習專案中，確定當前工作目錄很重要，因為接下來的檔案讀寫操作都會基於這個目錄進行。","metadata":{}},{"cell_type":"code","source":"HOME = os.getcwd()\nprint(HOME)","metadata":{"id":"x-vOupV4hVAt","executionInfo":{"status":"ok","timestamp":1674148374659,"user_tz":-300,"elapsed":9,"user":{"displayName":"Muhammad Moin","userId":"09308091267031599057"}},"execution":{"iopub.status.busy":"2024-08-20T02:29:34.162741Z","iopub.execute_input":"2024-08-20T02:29:34.162996Z","iopub.status.idle":"2024-08-20T02:29:34.169859Z","shell.execute_reply.started":"2024-08-20T02:29:34.162968Z","shell.execute_reply":"2024-08-20T02:29:34.168966Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"markdown","source":"我們可以執行 shell 指令 `nvidia-smi` 指令來查看 GPU 的狀態。\n\n`nvidia-smi` 這個指令會顯示目前系統中可用的 NVIDIA GPU 資訊，包括 GPU 型號、使用的驅動版本、當前的記憶體使用情況等。\n\n對於訓練深度學習模型，了解 GPU 的狀態非常重要，因為它會直接影響模型訓練的效能。","metadata":{}},{"cell_type":"code","source":"# 查看 GPU 的狀態。\n!nvidia-smi","metadata":{"id":"ixCtMpfygusf","outputId":"f8e76e5b-61fb-47f1-bb8e-a2a4e79ef407","executionInfo":{"status":"ok","timestamp":1674148373896,"user_tz":-300,"elapsed":905,"user":{"displayName":"Muhammad Moin","userId":"09308091267031599057"}},"execution":{"iopub.status.busy":"2024-08-20T02:29:34.171048Z","iopub.execute_input":"2024-08-20T02:29:34.171353Z","iopub.status.idle":"2024-08-20T02:29:35.257781Z","shell.execute_reply.started":"2024-08-20T02:29:34.171330Z","shell.execute_reply":"2024-08-20T02:29:35.256888Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Tue Aug 20 02:29:35 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   43C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   43C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"markdown","source":"在 IPython 或 Jupyter Notebook 中，\n- `!` 符號用來執行 shell 指令，這相當於直接在終端機中輸入指令。\n- `%` 符號用來執行 IPython 的 magic commands，不只包含呼叫 shell 指令，還有更高層次的操作。","metadata":{}},{"cell_type":"markdown","source":"## 1.3 安裝並匯入 `ultralytics`","metadata":{}},{"cell_type":"markdown","source":"[`ultralytics`](https://pypi.org/project/ultralytics/) 是 YOLOv8 的官方實作版本。","metadata":{}},{"cell_type":"code","source":"# 用 pip 安裝 ultralytics\n# --quiet 選項能減少安裝過程中的輸出訊息，使 pip 只會顯示必要的錯誤或警告。\n!pip install --quiet ultralytics\n\n# 匯入 ultralytics\nimport ultralytics","metadata":{"id":"zX_KHEfold1G","outputId":"655e67ad-a182-4019-e170-360d2943510b","executionInfo":{"status":"ok","timestamp":1674148392852,"user_tz":-300,"elapsed":14250,"user":{"displayName":"Muhammad Moin","userId":"09308091267031599057"}},"execution":{"iopub.status.busy":"2024-08-20T02:29:35.260538Z","iopub.execute_input":"2024-08-20T02:29:35.260839Z","iopub.status.idle":"2024-08-20T02:29:53.620156Z","shell.execute_reply.started":"2024-08-20T02:29:35.260813Z","shell.execute_reply":"2024-08-20T02:29:53.619386Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"[`ultralytics.checks()`](https://docs.ultralytics.com/reference/utils/checks/) 會檢查軟硬體配置（例如確認是否有正確版本的 PyTorch 以及 GPU 支援等），這樣可以確保 YOLOv8 模型順利運行。","metadata":{}},{"cell_type":"code","source":"# 查當前的系統環境是否適合 YOLOv8 運行\nultralytics.checks()","metadata":{"execution":{"iopub.status.busy":"2024-08-20T02:29:53.621272Z","iopub.execute_input":"2024-08-20T02:29:53.621672Z","iopub.status.idle":"2024-08-20T02:30:04.836957Z","shell.execute_reply.started":"2024-08-20T02:29:53.621646Z","shell.execute_reply":"2024-08-20T02:30:04.836086Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Ultralytics YOLOv8.2.79 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\nSetup complete ✅ (4 CPUs, 31.4 GB RAM, 5771.7/8062.4 GB disk)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"假設你的系統已成功安裝並配置了 YOLOv8，應該會顯示：\n\n```\nUltralytics YOLOv8.2.78 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\nSetup complete ✅ (4 CPUs, 31.4 GB RAM, 5771.7/8062.4 GB disk)\n```\n具體情況如下：\n\n1. **Ultralytics YOLOv8.2.78**：這表示你安裝的 YOLOv8 版本是 8.2.78。\n2. **Python-3.10.13**：你正在使用 Python 3.10.13 版本。\n3. **torch-2.1.2**：你安裝的 PyTorch 版本是 2.1.2，這是 YOLOv8 依賴的重要深度學習框架。\n4. **CUDA:0 (Tesla T4, 15095MiB)**：這表示系統檢測到一張 NVIDIA Tesla T4 GPU，並且這張 GPU 擁有 15095MB 的顯示卡記憶體。CUDA 是用來加速 GPU 計算的技術。\n5. **Setup complete**：這表示 YOLOv8 的環境配置已經完成，可以開始使用。\n6. **4 CPUs, 31.4 GB RAM, 5771.7/8062.4 GB disk**：這表示你的系統有 4 個 CPU，31.4 GB 的記憶體，以及 8062.4 GB 的硬碟空間，其中 5771.7 GB 已經被使用。\n\n這個結果確認了你的系統環境配置良好，適合進行 YOLOv8 模型的訓練與推理。\n","metadata":{}},{"cell_type":"markdown","source":"## 1.4 安裝 `roboflow` 並載入資料集","metadata":{}},{"cell_type":"markdown","source":"**Roboflow** 是一個提供影像資料集管理與標註工具的平台。我們用 Roboflow 的 API （即 [`roboflow`](https://pypi.org/project/roboflow/) 套件）來載入現成的手語資料集。\n\n首先在當前工作目錄下創建一個名為 \"datasets\" 的資料夾。這個資料夾將用來存放我們即將下載和處理的資料集。","metadata":{}},{"cell_type":"code","source":"!mkdir {HOME}/datasets\n%cd {HOME}/datasets","metadata":{"execution":{"iopub.status.busy":"2024-08-20T02:30:04.838220Z","iopub.execute_input":"2024-08-20T02:30:04.838533Z","iopub.status.idle":"2024-08-20T02:30:05.839881Z","shell.execute_reply.started":"2024-08-20T02:30:04.838508Z","shell.execute_reply":"2024-08-20T02:30:05.838835Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"/kaggle/working/datasets\n","output_type":"stream"}]},{"cell_type":"code","source":"# 用 pip 安裝 roboflow\n!pip install --quiet roboflow","metadata":{"execution":{"iopub.status.busy":"2024-08-20T02:30:05.841418Z","iopub.execute_input":"2024-08-20T02:30:05.841747Z","iopub.status.idle":"2024-08-20T02:30:18.866339Z","shell.execute_reply.started":"2024-08-20T02:30:05.841706Z","shell.execute_reply":"2024-08-20T02:30:18.865242Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\njupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"下載資料集的流程如下。\n\n1. **取得 API 金鑰**：首先，你需要在 Roboflow 的平台上註冊並創建一個專案。註冊後，你可以在帳戶設定或專案設定中找到你的 API 金鑰。\n\n2. **使用 API 金鑰進行身份驗證**：在你的程式中，你需要將 API 金鑰傳遞給 Roboflow 的 API，以便進行身份驗證。例如，rf = Roboflow(api_key=\"你的API金鑰\") 這行程式碼就負責這項操作。\n\n3. **下載資料集**：一旦身份驗證成功，你就可以使用 API 來下載專案中的資料集。Roboflow 會根據你的請求，將資料集以你指定的格式（例如 YOLOv5 格式）打包並下載到你的工作環境中。","metadata":{}},{"cell_type":"code","source":"from roboflow import Roboflow\n\n# 初始化 Roboflow，並使用 API 金鑰進行身份驗證。\nrf = Roboflow(api_key=\"vQpY4GwAhAtrSZQTm2J0\")\n\n# 取得指定的工作區和專案。\n# 這份資料集是來自 David Lee 的工作區，專案名稱為 american-sign-language-letters。\nproject = rf.workspace(\"david-lee-d0rhs\").project(\"american-sign-language-letters\")\n\n# 從專案中下載資料集的版本 1，並指定格式為 \"yolov5\"。\ndataset = project.version(1).download(\"yolov5\")","metadata":{"id":"8CElZj-vi6Mj","outputId":"da85d23b-7d93-4ff6-c542-ac4b9ab086eb","executionInfo":{"status":"ok","timestamp":1674148447149,"user_tz":-300,"elapsed":36536,"user":{"displayName":"Muhammad Moin","userId":"09308091267031599057"}},"execution":{"iopub.status.busy":"2024-08-20T02:30:18.868061Z","iopub.execute_input":"2024-08-20T02:30:18.868833Z","iopub.status.idle":"2024-08-20T02:30:21.856213Z","shell.execute_reply.started":"2024-08-20T02:30:18.868797Z","shell.execute_reply":"2024-08-20T02:30:21.855300Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"loading Roboflow workspace...\nloading Roboflow project...\n","output_type":"stream"},{"name":"stderr","text":"Downloading Dataset Version Zip in American-Sign-Language-Letters-1 to yolov5pytorch:: 100%|██████████| 22895/22895 [00:00<00:00, 46829.35it/s]","output_type":"stream"},{"name":"stdout","text":"\n","output_type":"stream"},{"name":"stderr","text":"\nExtracting Dataset Version Zip to American-Sign-Language-Letters-1 in yolov5pytorch:: 100%|██████████| 3458/3458 [00:00<00:00, 9737.26it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 1.5 準備資料集配置檔案","metadata":{}},{"cell_type":"markdown","source":"`dataset.location` 是一個包含下載資料集存放位置的變數。就我們載入的資料集而言，此變數的值是 `/kaggle/working/datasets/American-Sign-Language-Letters-1`。","metadata":{}},{"cell_type":"code","source":"# 切換到資料集所在的目錄\n%cd {HOME}\n%cd {dataset.location}","metadata":{"id":"mbBeu_eFj4J3","outputId":"9c67a729-0bb1-462d-d4aa-658852214a69","executionInfo":{"status":"ok","timestamp":1674129659491,"user_tz":-300,"elapsed":16,"user":{"displayName":"Muhammad Moin","userId":"09308091267031599057"}},"execution":{"iopub.status.busy":"2024-08-20T02:30:21.857733Z","iopub.execute_input":"2024-08-20T02:30:21.858162Z","iopub.status.idle":"2024-08-20T02:30:21.865272Z","shell.execute_reply.started":"2024-08-20T02:30:21.858129Z","shell.execute_reply":"2024-08-20T02:30:21.864422Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"/kaggle/working\n/kaggle/working/datasets/American-Sign-Language-Letters-1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"現在的目錄底下有一個名為 `data.yaml` 的檔案，它是 YOLOv5 的配置檔案，通常包含資料集的相關資訊，例如類別、訓練和驗證集的位置等。\n\n我們使用 `!cat` 指令來顯示 `data.yaml` 檔案的內容。","metadata":{}},{"cell_type":"code","source":"# 顯示配置檔案的內容，包含類別、訓練和驗證集的位置等。\n!cat {dataset.location}/data.yaml","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-20T02:30:21.866529Z","iopub.execute_input":"2024-08-20T02:30:21.866842Z","iopub.status.idle":"2024-08-20T02:30:22.900308Z","shell.execute_reply.started":"2024-08-20T02:30:21.866819Z","shell.execute_reply":"2024-08-20T02:30:22.899178Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"names:\n- A\n- B\n- C\n- D\n- E\n- F\n- G\n- H\n- I\n- J\n- K\n- L\n- M\n- N\n- O\n- P\n- Q\n- R\n- S\n- T\n- U\n- V\n- W\n- X\n- Y\n- Z\nnc: 26\ntrain: American-Sign-Language-Letters-1/train/images\nval: American-Sign-Language-Letters-1/valid/images\n","output_type":"stream"}]},{"cell_type":"markdown","source":"這段結果顯示了資料集的 `data.yaml` 配置檔案內容，並指出資料集包含以下幾個主要部分：\n\n1. **`names`**：列出了資料集中所有的類別標籤，從 A 到 Z，共 26 個字母。這表示資料集的目標是辨識美國手語中的26個字母。\n   \n2. **`nc`**：表示資料集的類別數目，即 26 個字母。\n\n3. **`train`**：指向訓練集影像的路徑 `American-Sign-Language-Letters-1/train/images`，這是模型訓練時使用的資料。\n\n4. **`val`**：指向驗證集影像的路徑 `American-Sign-Language-Letters-1/valid/images`，這是模型訓練過程中用來評估效能的資料。\n","metadata":{}},{"cell_type":"markdown","source":"我們要在 `data.yaml` 檔案的末尾加入一行 `path: .`，這明確指定資料集的根目錄位置。\n- `echo` 指令的作用是將 \"path: .\" 這行文字輸出。\n- 這項輸出經由管道符號 `|` 傳給下一個指令。\n- `tee -a` 的作用是同時將輸出顯示在終端，並寫入指定檔案中，不會覆蓋檔案的現有內容。\n","metadata":{}},{"cell_type":"code","source":"!echo \"path: .\" | tee -a data.yaml","metadata":{"execution":{"iopub.status.busy":"2024-08-20T02:30:22.901953Z","iopub.execute_input":"2024-08-20T02:30:22.902265Z","iopub.status.idle":"2024-08-20T02:30:23.904119Z","shell.execute_reply.started":"2024-08-20T02:30:22.902237Z","shell.execute_reply":"2024-08-20T02:30:23.902955Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"path: .\n","output_type":"stream"}]},{"cell_type":"code","source":"!cat {dataset.location}/data.yaml","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-20T02:30:23.905564Z","iopub.execute_input":"2024-08-20T02:30:23.905876Z","iopub.status.idle":"2024-08-20T02:30:24.896024Z","shell.execute_reply.started":"2024-08-20T02:30:23.905849Z","shell.execute_reply":"2024-08-20T02:30:24.894902Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"names:\n- A\n- B\n- C\n- D\n- E\n- F\n- G\n- H\n- I\n- J\n- K\n- L\n- M\n- N\n- O\n- P\n- Q\n- R\n- S\n- T\n- U\n- V\n- W\n- X\n- Y\n- Z\nnc: 26\ntrain: American-Sign-Language-Letters-1/train/images\nval: American-Sign-Language-Letters-1/valid/images\npath: .\n","output_type":"stream"}]},{"cell_type":"markdown","source":"觀察最後一行，`path: .` 應改已經加進去了。","metadata":{}},{"cell_type":"markdown","source":"## 1.6 使用 Ngrok 將 TensorBoard 公開到外網\n\n[**TensorBoard**](https://www.tensorflow.org/tensorboard?hl=zh-tw) 是 TensorFlow 提供的視覺化工具，旨在幫助開發者監控和分析機器學習模型的訓練過程。透過 TensorBoard，使用者可以查看模型的損失、精度、學習率等各種訓練指標，並且可以可視化神經網絡結構、觀察輸入數據和張量的分佈情況，甚至監控模型參數的變化過程。這些功能有助於開發者理解模型的訓練進度，調整超參數，並改善模型性能。\n\n在 TensorFlow 框架下進行訓練時，TensorBoard 的使用非常簡單——幾乎不用額外配置，只需在訓練過程中添加回調函數（callback）即可。\n\n只要下一行簡單的 shell 指令\n```shell\ntensorboard --logdir=runs\n```\n然後，你可以在瀏覽器中打開 http://localhost:6006 查看即時的訓練指標。\n\n雖然 YOLO 模型更接近 PyTorch 框架，但由於 PyTorch 提供了與 TensorBoard 整合的支持，所以使用者只需導入 TensorBoard 函式庫並設置 `SummaryWriter`，然後將訓練指標寫入到指定的日誌目錄。\n\n不過，更大的問題是，當我們在 Kaggle 的雲端環境中運行 TensorBoard 時，無法像在本機上那樣直接訪問 TensorBoard 的介面。為了解決這個問題，我們可以使用 **Ngrok** 這樣的工具，將 TensorBoard 的介面公開到網路上，這樣就能夠方便地從瀏覽器中訪問並監控訓練過程。","metadata":{}},{"cell_type":"markdown","source":"**[Ngrok](https://ngrok.com/)** 是一種反向代理（reverse proxy）工具，它可以讓你將本地主機（localhost）正在運行的服務公開到外網（Wide Area Network）上，讓你能夠從外部訪問這個服務，所以很適合在開發和測試中使用。\n\n","metadata":{}},{"cell_type":"markdown","source":"- 使用 `wget` 指令從網路下載 ngrok 的 Linux 版本壓縮包 (tgz 格式)。  \n- 使用 `tar` 指令解壓縮剛剛下載的 ngrok 壓縮包。`xvzf` 是 `tar` 指令的選項，分別代表解壓（x）、顯示過程（v）、解壓縮 gzip 文件（z）、指定文件（f）。","metadata":{}},{"cell_type":"code","source":"%cd {HOME} \n\n# 下載 Ngrok 的壓縮包 (tgz 格式)。\n!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n\n# 解壓縮\n!tar xvzf ngrok-v3-stable-linux-amd64.tgz","metadata":{"execution":{"iopub.status.busy":"2024-08-20T02:30:24.899470Z","iopub.execute_input":"2024-08-20T02:30:24.900002Z","iopub.status.idle":"2024-08-20T02:30:27.725120Z","shell.execute_reply.started":"2024-08-20T02:30:24.899974Z","shell.execute_reply":"2024-08-20T02:30:27.723905Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"--2024-08-20 02:30:25--  https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\nResolving bin.equinox.io (bin.equinox.io)... 52.202.168.65, 54.161.241.46, 18.205.222.128, ...\nConnecting to bin.equinox.io (bin.equinox.io)|52.202.168.65|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 8974299 (8.6M) [application/octet-stream]\nSaving to: 'ngrok-v3-stable-linux-amd64.tgz'\n\nngrok-v3-stable-lin 100%[===================>]   8.56M  29.7MB/s    in 0.3s    \n\n2024-08-20 02:30:26 (29.7 MB/s) - 'ngrok-v3-stable-linux-amd64.tgz' saved [8974299/8974299]\n\nngrok\n","output_type":"stream"}]},{"cell_type":"markdown","source":"`authtoken` 是 Ngrok 提供的一個指令，用來配置你的帳戶金鑰，這樣你就可以使用 ngrok 的服務了。請注意，這裡的 `authtoken` 是用來連接你的 ngrok 帳戶，你應該替換為你自己的金鑰。","metadata":{}},{"cell_type":"code","source":"# 執行解壓縮後的 ngrok 可執行檔，進行身份驗證。\n!./ngrok authtoken 2kHBHpxSXjxl0CpAB1voiE5Pqm8_3ystxDW9bBnpySQuxo6ZT","metadata":{"execution":{"iopub.status.busy":"2024-08-20T02:30:27.726780Z","iopub.execute_input":"2024-08-20T02:30:27.727187Z","iopub.status.idle":"2024-08-20T02:30:28.733425Z","shell.execute_reply.started":"2024-08-20T02:30:27.727150Z","shell.execute_reply":"2024-08-20T02:30:28.732455Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n","output_type":"stream"}]},{"cell_type":"code","source":"from urllib.request import urlopen\nfrom io import BytesIO\nfrom zipfile import ZipFile\nfrom subprocess import Popen\nfrom os import chmod\nfrom os.path import isfile\nimport json\nimport time\nimport psutil\n\ndef launch_tensorboard():\n    tb_process, ngrok_process = None, None\n\n    # 啟動 TensorBoard\n    # 如果 TensorBoard 尚未啟動，則啟動它\n    if not is_process_running('tensorboard'):\n        tb_command = 'tensorboard --logdir /kaggle/working/runs/ --host 0.0.0.0 --port 6006 --load_fast=false'\n        tb_process = run_cmd_async_unsafe(tb_command)\n    \n    # 創建 ngrok 隧道並印出其公共 URL\n    # 如果 ngrok 尚未啟動，則啟動它以創建一個 HTTP 隧道\n    if not is_process_running('ngrok'):\n        ngrok_process = run_cmd_async_unsafe('./ngrok http http://localhost:6006')\n        time.sleep(1)  # 等待 ngrok 啟動隧道\n    ngrok_api_res = urlopen('http://127.0.0.1:4040/api/tunnels', timeout=10)\n    ngrok_api_res = json.load(ngrok_api_res)\n    \n    # 確保 ngrok 隧道已經創建\n    assert len(ngrok_api_res['tunnels']) > 0, 'ngrok tunnel not found'\n    tb_public_url = ngrok_api_res['tunnels'][0]['public_url']\n    print(f'TensorBoard URL: {tb_public_url}')\n\n    return tb_process, ngrok_process\n\n# 非同步執行命令，雖不安全但簡單\ndef run_cmd_async_unsafe(cmd):\n    return Popen(cmd, shell=True)\n\n# 檢查指定名稱的程序是否正在運行\ndef is_process_running(process_name):\n    running_process_names = (proc.name() for proc in psutil.process_iter())\n    return process_name in running_process_names\n\n# 啟動 TensorBoard 並建立 ngrok 隧道\nlaunch_tensorboard()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-20T02:30:28.734897Z","iopub.execute_input":"2024-08-20T02:30:28.735224Z","iopub.status.idle":"2024-08-20T02:30:29.761558Z","shell.execute_reply.started":"2024-08-20T02:30:28.735197Z","shell.execute_reply":"2024-08-20T02:30:29.760116Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"TensorBoard URL: https://4d1f-35-193-231-61.ngrok-free.app\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(<Popen: returncode: None args: 'tensorboard --logdir /kaggle/working/runs/ -...>,\n <Popen: returncode: None args: './ngrok http http://localhost:6006'>)"},"metadata":{}},{"name":"stderr","text":"TensorBoard 2.15.1 at http://0.0.0.0:6006/ (Press CTRL+C to quit)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"簡要說明：\n\n- **launch_tensorboard() 函式**：這個函式啟動 TensorBoard 並通過 ngrok 創建一個公共 URL，使其能夠從外部訪問。這在 Kaggle Notebook 或其他雲端環境中特別有用，因為這些環境通常沒有直接的外部訪問權限。\n  \n- **run_cmd_async_unsafe() 函式**：這個輔助函式用來非同步執行 shell 命令。儘管它是「不安全」的，因為沒有進行額外的錯誤檢查，但它在簡單的情境下仍然有效。\n\n- **is_process_running() 函式**：這個函式用來檢查特定名稱的程序是否正在運行，通過使用 `psutil` 函式庫來檢查系統中當前正在運行的所有程序。\n\n這段程式碼主要用於在遠程或受端環境中啟動 TensorBoard 並使其通過 ngrok 隧道公開，使得你可以從外部監控訓練過程。","metadata":{}},{"cell_type":"markdown","source":"# 2. 訓練模型\n\n\n接下來正式進入模型的訓練。我們將會執行以下 shell 指令。\n\n```shell\n!yolo device=0,1 task=detect mode=train model=yolov8l.pt optimizer=\"auto\" batch=32 data={dataset.location}/data.yaml epochs=50 imgsz=800\n```\n\n它含有大量的關鍵字參數（keyword argument），我們在執行前先來做個詳細解釋。\n","metadata":{"id":"65k1QMPwjt63"}},{"cell_type":"markdown","source":"## 2.1 YOLO 指令參數解析\n\n\n### **`device=0,1`** 指定了要使用的加速裝置\n這裡表示使用 GPU 0 和 1 來加速訓練。\n\nKaggle 在 Session options 中免費提供「GPU T4 x2」、「GPU P100」、「TPU VM v3-8」等加速裝置，以下是它們的比較以及它們在 YOLO 模型訓練中的適用性分析。\n\n#### 比較與適用性分析\n\n1. **計算性能**:\n   - **TPU v3-8** 在 FP16（半精度浮點數）性能上遙遙領先，適合大規模的深度學習模型訓練和快速迭代。\n   - **Tesla T4 x2** 提供的雙卡配置能有效利用多 GPU 訓練並加速計算過程，特別是在分布式訓練中。\n   - **Tesla P100** 雖然沒有 Tensor 核心，但在 FP32 精度下依然表現強勁，適合需要更高精度訓練的任務。\n\n2. **記憶體大小**:\n   - **TPU v3-8** 擁有 128 GB 的 HBM 記憶體，適合處理極大規模的模型和資料集。\n   - **Tesla T4 x2** 的總記憶體為 32 GB，足夠訓練大多數 YOLO 模型。\n   - **Tesla P100** 擁有 16 GB HBM2 記憶體，對於中型模型是足夠的，但可能不足以處理更大的模型或更高解析度的圖像。\n\n3. **軟體支援**:\n   - **TPU v3-8** 需要使用 TensorFlow 或 JAX 進行訓練，並可能需要對 YOLO 模型進行一些修改和優化。\n   - **Tesla T4** 和 **P100** 支援更廣泛的深度學習框架，包括 PyTorch、TensorFlow、MXNet 等，這使得它們更加靈活，尤其是在使用 PyTorch 的情況下。\n\n#### 結論：哪一個最適合 YOLO 模型訓練？\n\n- **Tesla T4 x2** 是 YOLO 模型訓練的最佳選擇，特別是對於需要利用多 GPU 進行加速的情況。它的雙 GPU 配置能夠提供足夠的計算能力和記憶體來訓練大型模型，如 YOLOv8l 和 YOLOv8x，並且與 PyTorch 和 TensorFlow 等框架高度相容。\n\n- **Tesla P100** 可以用於中型模型的訓練，如 YOLOv8m 或 YOLOv8l，當計算資源有限且不需要 Tensor 核心加速時，P100 也是一個不錯的選擇。\n\n- **TPU v3-8** 適合非常大規模的訓練任務，特別是當使用 TensorFlow 或 JAX 進行開發時。然而，由於需要進行適配且對於 YOLO 這類 CNN 模型，GPU 可能更適合，因此 TPU 不一定是最理想的選擇。\n\n根據這些分析，**Tesla T4 x2** 是你在 Kaggle 上進行 YOLO 模型訓練的最佳選擇。\n\n### **`task=detect`** 表示執行物件偵測任務。\n- **`detect` 是物件偵測**，也是 YOLO 的核心任務，用於從影像或視頻中檢測並標註出各類物件的邊界框和類別標籤。\n- **`segment` 是語義分割**，它將影像中的每個像素分類到不同物件或背景中。YOLO 在這個任務中不僅檢測物件的邊界框，還提供每個物件的精確像素遮罩。\n- **`classify` 是圖像分類**，也就是整張影像分配到預定義的類別之一。YOLO 在這個模式下會忽略物件的空間位置，只關心影像中是否存在某個類別的物件。\n- **`pose` 是姿態估計**，可進行人體姿態估計，識別並標注人體的各個關鍵點（如肩膀、肘部、膝蓋等），從而推測人體的姿態。\n- **`track` 是物件追蹤**，它結合物件偵測與追蹤技術，用於在影片序列中對物件進行持續追蹤。這個任務可以跟隨特定物件在多幀影像中的移動軌跡。\n\n\n### **`mode=train`** 表示訓練模式。\n- YOLO 提供了多種模式來應對不同的任務需求，包括 `train`（訓練）、`val`（驗證）、`predict`（預測）、`export`（匯出）、`track`（追蹤）和 `benchmark`（基準測試）。\n- **`train` 是訓練模式**，用於從頭開始或基於預訓練模型進行模型訓練。\n    - 在這個模式下，YOLO 模型會通過反向傳播算法（通常是基於梯度下降法的優化器，如 SGD 或 Adam）學習訓練數據中的特徵，調整模型參數，使得模型能夠準確地執行目標任務，如物件偵測或分類。\n    - 此外，YOLO 會根據配置的超參數（如學習率、批次大小、增強技術等）進行多個 epoch 的訓練，每個 epoch 都會遍歷整個訓練數據集。\n    - 訓練過程中，模型的性能指標（如損失函數、精確度等）會被記錄下來，用於監控訓練進度。\n- **`val` 是驗證（validation）模式**，用來驗證集上評估模型的性能。這個模式不會進行訓練，而是通過載入預訓練或訓練過的模型，對驗證數據進行推理，並計算如 mAP（mean Average Precision）、精確度、召回率等指標。`val` 模式通常在訓練過程結束後或訓練過程中間隔性地運行，以檢查模型的表現並確保模型不會過擬合。\n- **`predict` 是預測模式**，用於對新數據進行推理和檢測。這個模式使用訓練好的模型，對給定的輸入圖像或影像進行物件檢測，並輸出檢測結果。`predict` 模式適用於實際應用中的模型部署，如對影片串流或靜態圖片進行即時物件檢測。\n- **`export` 是匯出模式**，用於將模型轉換成不同的格式以便於部署。這些格式可能包括 **ONNX**、**TensorFlow Lite**（tflite）、**CoreML**、**TorchScript** 等。當需要在不同的推理框架或硬體平台上部署模型時使用 `export` 模式。匯出的模型可以在手機、嵌入式設備、瀏覽器等不同環境中運行。\n- **`track` 是追蹤模式**，用來對物件進行跟蹤。這個模式通常與物件偵測結合，能夠在影片或連續圖像中追蹤同一物件的運動。適用於監控系統、自動駕駛、智慧交通等場景，跟蹤在一系列影像中移動的物件。\n- **`benchmark` 是基準測試模式**，用於測試模型的性能和資源需求。這個模式會運行一些基準測試來評估模型的推理速度、計算需求、記憶體使用等。`benchmark` 模式常用在部署前測試模型性能，以確保模型在特定硬體環境中的表現符合要求。\n\n### **`model=yolov8l.pt`** 指定了預訓練模型的路徑或名稱\n- 這裡使用 YOLOv8 large (yolov8l) 版本。\n- YOLOv8 提供了多個不同大小和複雜度的模型版本，以滿足不同應用場景的需求。\n- 層數和參數愈多，準確度越高，可以讓模型學習到更複雜的特徵，但也需要越多資源來計算和推理。\n- yolov8l 以外的其他選項：YOLOv8n（輕量版）、YOLOv8s（小型版）、YOLOv8m（中型版）、YOLOv8x（超大型版）。\n\n### **`optimizer=\"auto\"`** 讓 YOLOv8 自動選擇最合適的優化器。\n- SGD、Adam、AdamW、RMSProp、AdaGrad 都是訓練深度學習模型時常用的優化器。\n- 在 YOLOv8 中，預設的優化器通常是 AdamW，因為它在大多數深度學習任務中表現出良好的效果。\n- 如果你的模型存在過擬合問題，可以考慮使用 AdamW 或 SGD。如果你的資料集非常大，並且希望更穩定的訓練過程，可以選擇 SGD。\n\n### **`batch=32`** 設定批次大小為 32\n- 這意味著每次訓練會同時處理 32 張圖片。\n- 批次大小會影響 GPU 記憶體的使用和模型的收斂速度。\n- 較大的批次通常能帶來更穩定的梯度估計，但也需要更多的記憶體。\n\n### **`data={dataset.location}/data.yaml`** 指定了資料集的配置檔案位置。\n- 這裡使用我們之前準備好的 `data.yaml`。\n- 在 YOLO 訓練過程中，**資料集配置檔案是必須的**。它告訴模型在哪裡找到訓練集和驗證集、如何處理這些數據、以及模型應該學習哪些類別。\n\n### **`epochs=50`** 設定訓練迭代次數為 50。\n- 訓練的 epoch 會影響最終的模型性能和訓練時間。\n- 另外，在 YOLO 模型的訓練過程中，**早停策略**（Early Stopping）是一種防止過擬合的技術。\n    - 它可以在訓練過程中監控模型的性能指標（如驗證集上的損失或精確度），並在模型性能停止改善時提前終止訓練。\n    - `patience`、`delta`、`monitor` 等超參數都跟早停策略有關。\n- 這些參數應根據資料集大小和模型收斂情況來調整。\n\n### **`imgsz=800`** 設定影像大小為 800 像素\n- `imgsz` 是用來指定訓練時將所有輸入圖片調整為統一尺寸的參數，這對於 CNN 模型（如 YOLO）至關重要，因為它使得網絡中的卷積層和池化層能夠一致地處理特徵圖。\n- 關於特徵尺度\n    - 如果原始圖片過小，放大到 800x800 可能會導致像素失真，從而影響模型學習到的特徵。\n    - 如果原始圖片過大，縮小到 800x800 則可能會丟失一些細節，這可能會影響模型對小物件的偵測能力。\n    - 所以圖片尺寸必須適當，才有助於模型學習不同大小物件的特徵\n- 關於計算量與性能\n    - 影像大小直接影響模型的計算量和性能。\n    - 更大的影像可以保留更多的細節，但也會增加計算量。\n","metadata":{}},{"cell_type":"code","source":"%cd {HOME} \n\n!yolo device=0,1 task=detect mode=train model=yolov8l.pt optimizer=\"auto\" batch=32 data={dataset.location}/data.yaml epochs=50 imgsz=800","metadata":{"id":"SA3S___qj88u","outputId":"4fa11aba-81bd-4bd5-8111-d7640ca3f6c9","executionInfo":{"status":"ok","timestamp":1674136270335,"user_tz":-300,"elapsed":163152,"user":{"displayName":"Muhammad Moin","userId":"09308091267031599057"}},"execution":{"iopub.status.busy":"2024-08-20T02:31:49.718975Z","iopub.execute_input":"2024-08-20T02:31:49.719491Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"/kaggle/working\nDownloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8l.pt to 'yolov8l.pt'...\n100%|███████████████████████████████████████| 83.7M/83.7M [00:00<00:00, 191MB/s]\nUltralytics YOLOv8.2.79 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                      CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8l.pt, data=/kaggle/working/datasets/American-Sign-Language-Letters-1/data.yaml, epochs=50, time=None, patience=100, batch=32, imgsz=800, save=True, save_period=-1, cache=False, device=(0, 1), workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\nDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 14.2MB/s]\nOverriding model.yaml nc=80 with nc=26\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 22        [15, 18, 21]  1   5602846  ultralytics.nn.modules.head.Detect           [26, [256, 512, 512]]         \nModel summary: 365 layers, 43,649,886 parameters, 43,649,870 gradients, 165.5 GFLOPs\n\nTransferred 589/595 items from pretrained weights\n\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python3.10 -m torch.distributed.run --nproc_per_node 2 --master_port 40559 /root/.config/Ultralytics/DDP/_temp_gnkc1t4k139971922287280.py\nUltralytics YOLOv8.2.79 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                      CUDA:1 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\nOverriding model.yaml nc=80 with nc=26\nTransferred 589/595 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\nDownloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n100%|██████████████████████████████████████| 6.25M/6.25M [00:00<00:00, 71.2MB/s]\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/datasets/American-Sign-Language-Letters-1/train/\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/datasets/American-Sign-Language-Letters-1/train/labels.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/datasets/American-Sign-Language-Letters-1/valid/la\u001b[0m\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/datasets/American-Sign-Language-Letters-1/valid/labels.cache\nPlotting labels to runs/detect/train/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 800 train, 800 val\nUsing 4 dataloader workers\nLogging results to \u001b[1mruns/detect/train\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       1/50      15.3G       1.15      3.917      1.677          5        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144     0.0984      0.323      0.105     0.0534\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       2/50      15.3G       1.14      2.767      1.615          8        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144     0.0052     0.0425    0.00315    0.00164\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       3/50      15.1G      1.108      2.556      1.584         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.168      0.116     0.0246     0.0125\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       4/50      15.4G      1.136      2.406      1.569          7        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.193      0.213     0.0842      0.048\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       5/50      15.4G      1.119      2.318      1.596          8        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.504       0.37      0.315      0.215\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       6/50      15.4G      1.087      2.202      1.548         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.331      0.636      0.563       0.41\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       7/50      15.3G       1.02      1.983      1.485          9        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.435      0.567      0.524      0.321\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       8/50      15.1G     0.9735      1.916      1.454          9        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.447      0.751      0.698      0.553\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n       9/50      15.4G      0.987      1.816      1.441          7        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.548      0.728      0.721       0.57\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      10/50      15.1G     0.9179       1.71      1.395         13        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.596      0.686      0.709      0.557\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      11/50      15.4G     0.8908      1.724      1.382          9        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.685      0.684      0.792      0.607\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      12/50      15.3G     0.9165      1.633      1.404         11        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.714      0.649      0.786      0.604\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      13/50      15.4G     0.8773      1.581      1.386          5        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.647      0.812      0.831      0.668\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      14/50      15.4G     0.8726      1.582      1.358          6        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.753        0.5      0.655      0.485\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      15/50      15.4G      0.833      1.486      1.334         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.609      0.761      0.812      0.629\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      16/50      15.1G      0.835       1.44      1.318          7        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.717      0.742      0.793      0.607\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      17/50      15.3G     0.7836      1.349      1.289          8        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144       0.81      0.739      0.874       0.68\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      18/50      15.4G     0.7677      1.288      1.258         15        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.778      0.835      0.892      0.707\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      19/50      15.4G     0.8234      1.282      1.307          8        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.726      0.735      0.836      0.644\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      20/50      15.3G     0.8057      1.273      1.298          9        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.849      0.764      0.898      0.717\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      21/50      15.4G     0.7896      1.228      1.285          9        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.802      0.812      0.883      0.704\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      22/50      15.4G     0.7757      1.225      1.282         11        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.822      0.834      0.919      0.745\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      23/50      15.4G     0.7853      1.218      1.282         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.746      0.819      0.908      0.749\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      24/50      15.4G     0.7471      1.117      1.242         12        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.859      0.795      0.912      0.676\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      25/50      15.4G     0.7664      1.129      1.271         10        800: 1\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.898      0.835       0.93      0.729\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      26/50      15.4G     0.7279      1.101      1.239         42        800:  ","output_type":"stream"}]},{"cell_type":"markdown","source":"上一段程式碼區塊的輸出訊息分別對應了模型訓練過程中的不同步驟，以下章節是每一部分的解釋。\n\n## 2.2 訓練過程(1) — 環境初始化\n\n```txt\n/kaggle/working\nUltralytics YOLOv8.2.79 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla T4, 15095MiB)\n                                                      CUDA:1 (Tesla T4, 15095MiB)\n```\n\n這部分顯示了你當前的工作目錄 `/kaggle/working`，以及 YOLOv8 和相關環境的初始化資訊。特別是：\n- 使用的是 YOLOv8.2.79 版本。\n- Python 版本是 3.10.13，並且使用的是 torch-2.1.2 (PyTorch)。\n- 系統檢測到兩個 Tesla T4 GPU，各自有 15,095 MB 的顯示記憶體（顯示卡記憶體）。\n\n## 2.3 訓練過程(2) — 超參數設置\n\n```txt\nengine/trainer: task=detect, mode=train, model=yolov8l.pt, data=/kaggle/working/datasets/American-Sign-Language-Letters-1/data.yaml, epochs=50, ...\n```\n\n這段描述了 YOLOv8 模型訓練的所有**超參數**，例如前幾項\n- `task=detect` 表示執行物件偵測任務。\n- `mode=train` 表示進行訓練。\n- `model=yolov8l.pt` 是使用的 **YOLOv8 large** 預訓練模型。\n- `data=/kaggle/working/datasets/American-Sign-Language-Letters-1/data.yaml` 指定了資料集的配置文件。\n- `epochs=50` 設定訓練 50 個 epoch（迭代）。\n\n這些都是我們設定的。另外 YOLO 還有數十個預設的超參數，參見下表。               \n","metadata":{}},{"cell_type":"markdown","source":"### 2.3.1 超參數總表\n\n| 超參數          | 值 | 定義 | 範疇 | 是否為預設 |\n|----------------|---|-----|------------------|-----------|\n| task           | detect | 任務類型（物件偵測） | 模型設定相關     | Yes |\n| mode           | train | 模型模式（訓練模式） | 模型設定相關     | Yes |\n| model          | yolov8l.pt | 使用的預訓練模型 | 模型設定相關     | No |\n| pretrained     | True | 是否使用預訓練模型 | 模型設定相關     | Yes |\n| single_cls     | False | 是否將所有物件視為單一類別進行訓練 | 模型設定相關     | Yes |\n| project        | None | 專案名稱 | 模型設定相關     | Yes |\n| exist_ok       | False | 是否覆蓋已存在的專案 | 模型設定相關     | Yes |\n| epochs         | 50 | 訓練的總迭代次數 | 訓練過程相關     | Yes |\n| batch          | 32 | 批次大小 | 訓練過程相關     | Yes |\n| optimizer      | auto | 優化器選擇 | 訓練過程相關     | Yes |\n| device         | (0, 1) | 使用的設備 | 訓練過程相關     | No |\n| workers        | 8 | 工作進程數量 | 訓練過程相關     | Yes |\n| amp            | True | 是否使用自動混合精度 | 訓練過程相關     | Yes |\n| lr0            | 0.01 | 初始學習率 | 學習率與優化相關 | Yes |\n| lrf            | 0.01 | 最終學習率 | 學習率與優化相關 | Yes |\n| momentum       | 0.937 | 動量 | 學習率與優化相關 | Yes |\n| weight_decay   | 0.0005 | 權重衰減 | 學習率與優化相關 | Yes |\n| imgsz          | 800 | 訓練影像的尺寸 | 資料增強與預處理 | Yes |\n| mosaic         | 1.0 | 是否使用 Mosaic 增強 | 資料增強與預處理 | Yes |\n| auto_augment   | randaugment | 自動增強策略 | 資料增強與預處理 | Yes |\n| hsv_h          | 0.015 | 色相調整 | 資料增強與預處理 | Yes |\n| hsv_s          | 0.7 | 飽和度調整 | 資料增強與預處理 | Yes |\n| hsv_v          | 0.4 | 亮度調整 | 資料增強與預處理 | Yes |\n| scale          | 0.5 | 縮放範圍 | 資料增強與預處理 | Yes |\n| translate      | 0.1 | 平移範圍 | 資料增強與預處理 | Yes |\n| shear          | 0.0 | 切變範圍 | 資料增強與預處理 | Yes |\n| flipud         | 0.0 | 上下翻轉機率 | 資料增強與預處理 | Yes |\n| fliplr         | 0.5 | 左右翻轉機率 | 資料增強與預處理 | Yes |\n| mixup          | 0.0 | 是否使用 Mixup 增強 | 資料增強與預處理 | Yes |\n| copy_paste     | 0.0 | 是否使用 Copy-Paste 增強 | 資料增強與預處理 | Yes |\n| erasing        | 0.4 | 隨機擦除概率 | 資料增強與預處理 | Yes |\n| crop_fraction  | 1.0 | 裁剪比例 | 資料增強與預處理 | Yes |\n| iou            | 0.7 | IoU 閾值 | 驗證與推理相關   | Yes |\n| max_det        | 300 | 每張影像最大檢測數量 | 驗證與推理相關   | Yes |\n| conf           | None | 信心閾值 | 驗證與推理相關   | Yes |\n| val            | True | 是否進行驗證 | 驗證與推理相關   | Yes |\n| nms            | False | 是否使用非極大值抑制 | 驗證與推理相關   | Yes |\n| save           | True | 是否保存模型 | 模型保存與紀錄   | Yes |\n| save_dir       | runs/detect/train2 | 保存模型的路徑 | 模型保存與紀錄   | No |\n| save_period    | -1 | 模型保存頻率 | 模型保存與紀錄   | Yes |\n| save_txt       | False | 是否保存文本結果 | 模型保存與紀錄   | Yes |\n| save_conf      | False | 是否保存信心分數 | 模型保存與紀錄   | Yes |\n| save_crop      | False | 是否保存裁剪圖像 | 模型保存與紀錄   | Yes |\n| save_json      | False | 是否保存 JSON | 模型保存與紀錄   | Yes |\n| save_hybrid    | False | 是否保存混合結果 | 模型保存與紀錄   | Yes |\n| plots          | True | 是否生成訓練過程的圖表 | 模型保存與紀錄   | Yes |\n| name           | train2 | 訓練的名稱 | 模型保存與紀錄   | No |\n| patience       | 100 | 訓練早停的耐心次數 | 其他設置         | No |\n| deterministic  | True | 是否使用確定性行為 | 其他設置         | Yes |\n| seed           | 0 | 隨機數種子 | 其他設置         | Yes |\n| resume         | False | 是否從上次中斷的地方繼續訓練 | 其他設置         | Yes |\n| freeze         | None | 冷凍層級 | 其他設置         | Yes |\n| verbose        | True | 是否顯示詳細訊息 | 其他設置         | Yes |\n| cos_lr         | False | 是否使用餘弦退火學習率 | 其他設置         | Yes |\n| time           | None | 訓練時間限制 | 其他設置         | Yes |\n| cache          | False | 是否快取資料 | 其他設置         | Yes |\n| close_mosaic   | 10 | 關閉 mosaic 的 epoch | 其他設置         | No |\n| fraction       | 1.0 | 使用的資料比例 | 其他設置         | Yes |\n| profile        | False | 是否進行性能分析 | 其他設置         | Yes |\n| multi_scale    | False | 是否使用多尺度訓練 | 其他設置         | Yes |\n| overlap_mask   | True | 是否使用重疊遮罩 | 其他設置         | No |\n| mask_ratio     | 4 | 遮罩比率 | 其他設置         | No |\n| dropout        | 0.0 | Dropout 比率 | 其他設置         | Yes |\n| split          | val | 驗證集劃分名稱 | 其他設置         | Yes |\n| half           | False | 是否使用半精度浮點數 | 其他設置         | Yes |\n| dnn            | False | 是否使用深度學習推理加速 | 其他設置         | Yes |\n| source         | None | 資料來源 | 其他設置         | Yes |\n| vid_stride     | 1 | 影片步長 | 其他設置         | Yes |\n| stream_buffer  | False | 是否使用串流緩衝 | 其他設置         | Yes |\n| visualize      | False | 是否可視化結果 | 其他設置         | Yes |\n| augment        | False | 是否增強資料 | 其他設置         | Yes |\n| agnostic_nms   | False | 是否使用類別不可知 NMS | 其他設置         | Yes |\n| classes        | None | 目標類別 | 其他設置         | Yes |\n| retina_masks   | False | 是否使用 Retina 遮罩 | 其他設置         | Yes |\n| embed          | None | 嵌入設置 | 其他設置         | Yes |\n| show           | False | 是否顯示訓練過程 | 其他設置         | Yes |\n| save_frames    | False | 是否保存影格 | 其他設置         | Yes |\n| line_width     | None | 邊界框線寬 | 其他設置         | Yes |\n| format         | torchscript | 模型格式 | 其他設置         | Yes |\n| keras          | False | 是否啟用 Keras 模式 | 其他設置         | Yes |\n| optimize       | False | 是否進行優化 | 其他設置         | Yes |\n| int8           | False | 是否使用 int8 量化 | 其他設置         | Yes |\n| dynamic        | False | 是否使用動態軟體 | 其他設置         | Yes |\n| simplify       | False | 是否簡化模型 | 其他設置         | Yes |\n| opset          | None | ONNX 操作集版本 | 其他設置         | Yes |\n| workspace      | 4 | 工作空間大小 | 其他設置         | Yes |\n| box            | 7.5 | Box 項損失 | 損失函數相關     | Yes |\n| cls            | 0.5 | Class 項損失 | 損失函數相關     | Yes |\n| dfl            | 1.5 | DFL 項損失 | 損失函數相關     | Yes |\n| pose           | 12.0 | Pose 項損失 | 損失函數相關     | Yes |\n| kobj           | 1.0 | 物件分類損失 | 損失函數相關     | Yes |\n| label_smoothing| 0.0 | 標籤平滑 | 損失函數相關     | Yes |\n| nbs            | 64 | 批次大小 | 損失函數相關     | Yes |\n| degrees        | 0.0 | 旋轉角度 | 損失函數相關     | Yes |\n| perspective    | 0.0 | 透視範圍 | 損失函數相關     | Yes |\n| bgr            | 0.0 | 是否使用 BGR 色彩順序 | 損失函數相關     | Yes |\n| cfg            | None | 配置檔案 | 配置文件相關     | Yes |\n| tracker        | botsort.yaml | 追蹤器配置 | 配置文件相關     | Yes |\n","metadata":{}},{"cell_type":"markdown","source":"## 2.4 訓練過程(3) — 模型架構初始化\n\n```\nOverriding model.yaml nc=80 with nc=26\n...\nModel summary: 365 layers, 43,649,886 parameters, 43,649,870 gradients, 165.5 GFLOPs\n```\n\n這部分顯示模型的架構資訊：\n- 原始模型支援 80 類別（`nc=80`），但根據資料集配置，將其重設為 26 類別（手語字母 A-Z）。\n- 模型總共有 365 層、43,649,886 個參數，且模型計算量為 165.5 GFLOPs。\n    - GFLOPs 代表 Giga Floating Point Operations per Second，即每秒執行的十億次浮點運算次數。\n- 中間省略的部分是模型結構的一覽表，請參考以下解釋。","metadata":{}},{"cell_type":"markdown","source":"### 2.4.1 YOLO 模型結構詳解\n\n```txt\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n 22        [15, 18, 21]  1   5602846  ultralytics.nn.modules.head.Detect           [26, [256, 512, 512]]      \n ```\n\n這段輸出來自 YOLOv8 模型的架構初始化部分，展示了模型的各層結構及其參數配置。每一橫列代表模型中的一層。以下是各欄位的解釋：\n\n##### 欄位解釋\n1. **from**：\n    - 這欄顯示了當前層的輸入來自哪一層。例如，`-1` 表示來自上一層，`[-1, 6]` 表示來自上一層和第 6 層的輸出。\n   \n2. **n**：\n   - 表示這一層中有多少次重複。例如，`1` 表示這一層只執行一次操作。\n\n3. **params**：\n   - 這一欄顯示了該層中可訓練的參數數量。例如，`1856` 表示這一層有 1,856 個參數。\n   \n4. **module**：\n   - 這欄顯示了該層所使用的模組的類型或名稱。例如，`ultralytics.nn.modules.conv.Conv` 表示這是一個卷積層，`C2f` 是一種特定的模組，是 YOLOv8 中常見的模組之一。\n\n5. **arguments**：\n   - 這一欄列出了構建該層所需的參數或配置。例如，`[3, 64, 3, 2]` 表示這個卷積層的輸入通道數為 3，輸出通道數為 64，卷積核（kernel）大小為 3，步長（stride）為 2。\n\n##### 舉例說明\n讓我們來看幾個具體的例子來理解這些欄位：\n\n- **第 0 行**：\n  ```\n  0  -1  1  1856  ultralytics.nn.modules.conv.Conv  [3, 64, 3, 2]  \n  ```\n  這表示第一層是一個**卷積層**（`Conv`），它的輸入來自上一層（這裡是模型的輸入），輸入通道數為 3（通常對應於 RGB 影像的 3 個通道），輸出通道數為 64，卷積核大小為 3，步長為 2。這層有 1856 個可訓練參數。\n\n- **第 2 行**：\n  ```\n  2  -1  3  279808  ultralytics.nn.modules.block.C2f  [128, 128, 3, True]\n  ```\n  這層是一個重複 3 次的 **`C2f` 模組** ，輸入通道數和輸出通道數都是 128，卷積核大小為 3，並且啟用了某個布林參數（可能與是否啟用 shortcut 有關）。這層有 279,808 個可訓練參數。\n\n- **第 22 行**：\n  ```\n  22  [15, 18, 21]  1  5602846  ultralytics.nn.modules.head.Detect  [26, [256, 512, 512]]\n  ```\n  這層是 YOLOv8 中的物件偵測頭（detection head），它接受第 15 層、第 18 層和第 21 層的輸出作為輸入，並且執行一次操作。這層有 5,602,846 個可訓練參數，並且配置了 26 個類別（例如對應 26 個手語字母），以及三個不同的特徵層（每個特徵層的通道數分別為 256、512 和 512）。\n\n##### 總結\n這段輸出詳細展示了 YOLOv8 模型的層級結構，每一層的輸入、類型、參數數量等資訊。這些資料對於了解模型的計算圖、調整模型架構、分析模型的複雜度，以及進一步優化模型都有很大的幫助。","metadata":{}},{"cell_type":"markdown","source":"\n## 2.5 訓練過程(4) — 載入預訓練權重\n\n```txt\nTransferred 589/595 items from pretrained weights\n```\n\n這代表成功載入了**預訓練權重**（pretrained weights），大部分權重都轉移到了新的模型中。\n\n## 2.6 訓練過程(5) — 分散式訓練初始化\n\n```txt\nDDP: debug command ...\n```\n\n這部分表明使用的是**分散式資料平行化**（Distributed Data Parallel, DDP）來加速訓練，在多個 GPU 上運行。\n\n## 2.7 訓練過程(6) — 啟動 TensorBoard \n\n```txt\nTensorBoard: Start with 'tensorboard --logdir runs/detect/train2', view at http://localhost:6006/\n```\n\n這段提示你可以啟動 **TensorBoard** 來可視化訓練過程，通過指定的 URL 查看訓練進度。透過 Ngrok 的反向代理，指定的 URL 為 https://ca45-34-46-212-221.ngrok-free.app 。\n\n## 2.8 訓練過程(7) — 自動混合精度（AMP）檢查\n\n```txt\nAMP: running Automatic Mixed Precision (AMP) checks with YOLOv8n...\nAMP: checks passed ✅\n```\n\n這部分顯示 YOLOv8 正在執行**自動混合精度**（Automatic Mixed Precision, AMP）檢查，以提高訓練效能並降低記憶體消耗，檢查順利通過。\n\nAMP 是一種深度學習訓練技術，它通過在訓練過程中動態選擇不同精度的浮點數（如 FP16 和 FP32），來加速模型訓練，同時節省記憶體使用量。\n\n## 2.9 訓練過程(8) — 資料載入和資料增強\n\n```txt\ntrain: Scanning /kaggle/working/datasets/American-Sign-Language-Letters-1/train/\nalbumentations: Blur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, ...\nval: Scanning /kaggle/working/datasets/American-Sign-Language-Letters-1/valid/...\n```\n\n這部分的 `train` 和 `val` 顯示了訓練和驗證集的載入過程。\n\n`albumentations` 那一行是應用於資料集的**圖像增強技術**（image augmentation），這是深度學習模型訓練中的一個常見策略，用來提高模型的泛化能力和防止過擬合。\n\nYOLOv8 在訓練過程中應用了以下增強技術：\n- Blur：對圖像應用**隨機模糊**。\n- MedianBlur：使用**中值模糊**技術，這在降噪中非常有效。\n- ToGray：將圖像轉換為**灰階**圖像。\n- CLAHE：對比度受限的**自適應直方圖均衡化**（CLAHE），這是一種提高圖像對比度的技術。\n\n## 2.10 訓練過程(9) — 優化器自動選擇\n\n```txt\noptimizer: 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', ...\n```\n這部分顯示 YOLOv8 自動選擇了最佳的**優化器**（optimizer）——[AdamW](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html)，忽略了手動設置的初始學習率和動量，根據模型和資料集特性來調整。\n\n## 2.11 訓練過程(10) — 訓練啟動\n\n```txt\nImage sizes 800 train, 800 val\nUsing 4 dataloader workers\nLogging results to runs/detect/train2\nStarting training for 50 epochs...\n```\n\n這部分顯示訓練正式開始：\n- 使用的影像尺寸為 800x800 像素。\n- 訓練過程中使用 4 個資料載入器（data loader）程序。\n- 訓練結果會記錄到 `runs/detect/train2` 資料夾中。\n- 訓練將持續 50 個 epoch。","metadata":{}},{"cell_type":"markdown","source":"\n### 11. 訓練報告\n在 YOLOv8 的訓練過程中，每個 epoch 結束時都會引出一張表格來總結該次 epoch 的訓練結果和模型的性能評估。以下是這張表格中各個欄位的解釋：\n\n#### 1. Epoch 行\n```\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n      40/50      15.4G     0.6468     0.7795      1.187          5        800: 1\n```\n\n- **Epoch**：表示目前正在訓練的第幾個 epoch 以及總共的 epoch 數。例如，`40/50` 表示這是第 40 個 epoch，總共有 50 個 epoch。\n  \n- **GPU_mem**：當前使用的 GPU 記憶體量，這裡顯示為 `15.4G`，表示使用了 15.4 GB 的顯示卡記憶體（顯示記憶體）。\n\n- **box_loss**：表示**邊界框回歸損失**（Bounding Box Regression Loss），這是模型在預測物件邊界框時的誤差。損失越小，表示模型預測的邊界框越接近真實值。\n\n- **cls_loss**：表示**分類損失**（Classification Loss），這是模型在預測物件類別時的誤差。損失越小，表示模型在判斷物件類別時越準確。\n\n- **dfl_loss**：表示**分佈焦點損失**（Distribution Focal Loss），這是 YOLOv8 使用的一種損失函數，用於改進邊界框的精度。\n\n- **Instances**：每張影像中物件的平均數量，這裡顯示為 `5`，表示每張影像中平均有 5 個物件。\n\n- **Size**：訓練影像的大小，這裡顯示為 `800: 1`，表示影像的尺寸為 800x800 像素，比例為 1:1。\n\n#### 2. 評估行\n```\n                 Class     Images  Instances      Box(P          R      mAP50  m\n                   all        144        144      0.941      0.874      0.952      0.761\n```\n\n- **Class**：這一行是指在所有類別上的平均結果。通常會列出各個類別的性能指標，但這裡匯總了所有類別的結果。\n\n- **Images**：用於驗證的影像數量，這裡顯示為 `144`，表示使用了 144 張影像來評估模型的性能。\n\n- **Instances**：驗證集中物件的總數，這裡顯示為 `144`，表示驗證集中有 144 個物件。\n\n- **Box(P)**：精確率（Precision），表示模型預測的物件中有多少是正確的。這裡顯示為 `0.941`，即 94.1% 的預測是正確的。\n\n- **R**：召回率（Recall），表示實際存在的物件中有多少被模型正確檢測出來。這裡顯示為 `0.874`，即 87.4% 的實際物件被檢測出來。\n\n- **mAP50**：Mean Average Precision at IoU=0.50，這是物件偵測中的一個重要指標，表示在 IoU（Intersection over Union）= 0.50 門檻下的平均精度。這裡顯示為 `0.952`，即 95.2%。\n\n- **mAP50-95**：Mean Average Precision at IoU=0.50:0.95，這是更嚴格的評估標準，表示在多個 IoU 門檻下的平均精度。這裡顯示為 `0.761`，即 76.1%。\n\n#### 總結\n這張表格總結了每個 epoch 訓練結束後的模型性能：\n\n- **損失函數**（box_loss, cls_loss, dfl_loss）表明了模型的學習情況，損失越小越好。\n- **精確率**（P）和**召回率**（R）反映了模型在預測中的精度和全面性。\n- **mAP50** 和 **mAP50-95** 是物件偵測任務的核心指標，分別表示在不同 IoU 門檻下的平均精度，這些數值越高越好。\n\n通過這些指標，你可以判斷模型在訓練過程中的表現如何，並且可以根據這些結果來調整模型和參數以獲得更好的性能。","metadata":{}},{"cell_type":"code","source":"!ls {HOME}/runs/detect/train2/","metadata":{"id":"VIdYdhQjT1pR","executionInfo":{"status":"ok","timestamp":1674136504860,"user_tz":-300,"elapsed":699,"user":{"displayName":"Muhammad Moin","userId":"09308091267031599057"}},"outputId":"7081582e-e8a6-41bb-f2de-5c37b824c0fa","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#**Displaying the Confusion Matrix**","metadata":{"id":"dRT8XUB2T-rs"}},{"cell_type":"code","source":"%cd {HOME}\nImage(filename=f'{HOME}/runs/detect/train2/confusion_matrix.png', width=900)","metadata":{"id":"i8rzAG4LUDuB","executionInfo":{"status":"ok","timestamp":1674136564876,"user_tz":-300,"elapsed":1539,"user":{"displayName":"Muhammad Moin","userId":"09308091267031599057"}},"outputId":"e4139f4f-baeb-4380-98bb-ce4c5d4e7ef9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#**Training and Validation Loss**","metadata":{"id":"PZT7Yj__UPQl"}},{"cell_type":"code","source":"%cd {HOME}\nImage(filename=f'{HOME}/runs/detect/train2/results.png', width=600)","metadata":{"id":"guhGMMJxUPak","executionInfo":{"status":"ok","timestamp":1674136596088,"user_tz":-300,"elapsed":1721,"user":{"displayName":"Muhammad Moin","userId":"09308091267031599057"}},"outputId":"742beaab-465d-454d-a824-0997080c4c11","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd {HOME}\nImage(filename=f'{HOME}/runs/detect/train2/val_batch0_pred.jpg', width=600)","metadata":{"id":"T1QPiDrRUaFt","executionInfo":{"status":"ok","timestamp":1674136630168,"user_tz":-300,"elapsed":1976,"user":{"displayName":"Muhammad Moin","userId":"09308091267031599057"}},"outputId":"6a848d38-5b6a-423d-8756-8de9e841c256","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#**Validate Custom Model**","metadata":{"id":"iIzpjss8p242"}},{"cell_type":"code","source":"%cd {HOME}\n\n!yolo task=detect mode=val model={HOME}/runs/detect/train2/weights/best.pt data={dataset.location}/data.yaml","metadata":{"id":"ksNb0J6akcKT","executionInfo":{"status":"ok","timestamp":1674125662255,"user_tz":-300,"elapsed":28982,"user":{"displayName":"Muhammad Moin","userId":"09308091267031599057"}},"outputId":"da185407-f678-43e9-d4ed-4a7b9e3ab5ca","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#**Inference with Custom Model**","metadata":{"id":"lNwT90FUquDP"}},{"cell_type":"code","source":"%cd {HOME}\n!yolo task=detect mode=predict model={HOME}/runs/detect/train2/weights/best.pt conf=0.25 source={dataset.location}/test/images","metadata":{"id":"hHh4joWOqeIg","executionInfo":{"status":"ok","timestamp":1674125781032,"user_tz":-300,"elapsed":10869,"user":{"displayName":"Muhammad Moin","userId":"09308091267031599057"}},"outputId":"4e0fa895-4197-490a-9caa-cc81a8c381bc","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for image_path in glob.glob(f'{HOME}/runs/detect/predict/*.jpg')[:3]:\n      display(Image(filename=image_path, width=600))\n      print(\"\\n\")","metadata":{"id":"HBeWcTQiq7_k","executionInfo":{"status":"ok","timestamp":1674125861842,"user_tz":-300,"elapsed":1377,"user":{"displayName":"Muhammad Moin","userId":"09308091267031599057"}},"outputId":"7d603f5a-bd42-48c9-c7d1-bd6713cd998a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#**Testing on a Demo Video**","metadata":{"id":"Fq2qoyOQtZOH"}},{"cell_type":"code","source":"%cd {HOME}\n!yolo task=detect mode=predict model={HOME}/runs/best.pt conf=0.25 source='/content/demovideo/testvideo1.mp4'","metadata":{"id":"MwvKhrGlrLc4","executionInfo":{"status":"ok","timestamp":1674126743342,"user_tz":-300,"elapsed":316833,"user":{"displayName":"Muhammad Moin","userId":"09308091267031599057"}},"outputId":"665cb40c-c011-4099-b03a-3dce2b5c5879","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#**Display the Demo Video**","metadata":{"id":"-nzzls6Mwo8U"}},{"cell_type":"code","source":"!rm \"/content/result_compressed.mp4\"","metadata":{"id":"x8vsM8ZztfOG","executionInfo":{"status":"ok","timestamp":1674127288287,"user_tz":-300,"elapsed":689,"user":{"displayName":"Muhammad Moin","userId":"09308091267031599057"}},"outputId":"263bb773-b845-4426-be15-ee621f875d86","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import HTML\nfrom base64 import b64encode\nimport os\n\n# Input video path\nsave_path = '/content/runs/detect/predict2/testvideo1.mp4'\n\n# Compressed video path\ncompressed_path = \"/content/result_compressed.mp4\"\n\nos.system(f\"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}\")\n\n# Show video\nmp4 = open(compressed_path,'rb').read()\ndata_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\nHTML(\"\"\"\n<video width=400 controls>\n      <source src=\"%s\" type=\"video/mp4\">\n</video>\n\"\"\" % data_url)","metadata":{"id":"Ep7iJPcKwuCx","executionInfo":{"status":"ok","timestamp":1674127520495,"user_tz":-300,"elapsed":231680,"user":{"displayName":"Muhammad Moin","userId":"09308091267031599057"}},"outputId":"6a1d73db-9b6b-468e-e4ca-171146162cd8","trusted":true},"execution_count":null,"outputs":[]}]}